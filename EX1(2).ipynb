{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "The n-dimensional tensor mastery challenge: Combine the `Head` and `MultiHeadAttention` into one class that processes all the heads in parallel, treating the heads as another batch dimension (answer is in nanoGPT).\n",
    "\n",
    "You can even process the calculation for q, k, v in parallel by combining them into a \"batch_dimension\" of 3 and splitting afterwards. Use nn.Linear instead of torch.randn!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Vocabulary\n",
    "path = './data/HarryPotterPreprocessed.txt'\n",
    "with open(path, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "chars = sorted(list(set(text)))\n",
    "\n",
    "# Tokenization\n",
    "stoi = {s:i for i, s in enumerate(chars)}\n",
    "itos = {i:s for s, i in stoi.items()}\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "VOCAB_SIZE = len(chars)\n",
    "EMBEDDING_SIZE = 32\n",
    "CONTEXT_SIZE = 8\n",
    "BATCH_SIZE = 64\n",
    "MAX_STEPS = 5000\n",
    "LEARNING_RATE = 3E-4\n",
    "BLOCK_COUNT = 2\n",
    "NUM_HEADS = 4\n",
    "DROPOUT = 0.2\n",
    "HEAD_SIZE = EMBEDDING_SIZE // NUM_HEADS # How big Query, Key and Value matrices are\n",
    "device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "EVAL_INTERVAL = 500\n",
    "EVAL_LOSS_BATCHES = 200\n",
    "\n",
    "this_model_name = \"model_EX1(2).pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train & validation\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(data.shape[0] * 0.9)\n",
    "train_data, val_data = data[:n], data[n:]\n",
    "\n",
    "# Loader that returns a batch\n",
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(0, len(data) - CONTEXT_SIZE, (BATCH_SIZE, ))\n",
    "    x = torch.stack([data[i:i+CONTEXT_SIZE] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+CONTEXT_SIZE+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean loss for {EVAL_LOSS_BATCHES}x batches\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        losses = torch.zeros(EVAL_LOSS_BATCHES, device=device)\n",
    "        for i in tqdm(range(EVAL_LOSS_BATCHES)):\n",
    "            X, Y = get_batch(split)\n",
    "            _, loss = model(X, Y)\n",
    "            losses[i] = loss.item()\n",
    "        out[split] = losses.mean()  \n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Multiple Heads of Self-Attention in parallel \"\"\"\n",
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_heads = num_heads\n",
    "        self.head_size = head_size\n",
    "\n",
    "        # query, key & value matrix for n heads in parallel (must be split afterwards)\n",
    "        self.sa_heads = nn.Linear(EMBEDDING_SIZE, 3*num_heads*head_size, bias=False)\n",
    "        self.dropout = nn.Dropout(DROPOUT)\n",
    "\n",
    "        # Only For Multi Head\n",
    "        self.proj = nn.Linear(num_heads*head_size, EMBEDDING_SIZE) # back to original size (see 3b1b Value↑ matrix)\n",
    "        self.dropout2 = nn.Dropout(DROPOUT)\n",
    "\n",
    "        # since it's not a parameter of the model => register as buffer\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(CONTEXT_SIZE, CONTEXT_SIZE)))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        n_batch, n_context, n_emb = x.shape\n",
    "\n",
    "        x = self.sa_heads(x).view(n_batch, n_context, self.num_heads, 3*self.head_size).transpose(1, 2)\n",
    "        q, k, v = x.split(self.head_size, -1) # [n_batch, num_heads, n_context, head_size]\n",
    "\n",
    "        # Attention Score Table\n",
    "        wei = q @ k.transpose(-2, -1) * q.shape[-1]**-0.5 # [n_batch, num_heads, n_context, n_context]\n",
    "        # Masked Attention\n",
    "        wei = wei.masked_fill(self.tril[:n_context, :n_context] == 0, float('-inf'))\n",
    "        # Aggregation\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "\n",
    "        out = wei @ v # [n_batch, num_heads, n_context, head_size]\n",
    "        out = out.transpose(1, 2).reshape(n_batch, n_context, self.num_heads*self.head_size)\n",
    "\n",
    "        out = self.dropout2(self.proj(out)) # (n_batch, n_context, EMBEDDING_SIZE)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, in_feat):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_feat, in_feat * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * in_feat, in_feat),\n",
    "            nn.Dropout(DROPOUT)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer Block: Communication (MultiHead Attention) followed by computation (MLP - FeedForward)\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.sa_heads = CausalSelfAttention(n_heads, head_size)\n",
    "        self.ffwd = FeedForward(EMBEDDING_SIZE)\n",
    "\n",
    "        self.ln1 = nn.LayerNorm(EMBEDDING_SIZE)\n",
    "        self.ln2 = nn.LayerNorm(EMBEDDING_SIZE)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x + because their are residual connections around Masked Multi-Head Attention and Feed Forward (see Transformer Architecture)\n",
    "        x = x + self.sa_heads(self.ln1(x)) # (BATCH_SIZE, CONTEXT_SIZE, num_heads*head_size)\n",
    "        x = x + self.ffwd(self.ln2(x)) # (BATCH_SIZE, CONTEXT_SIZE, num_heads*head_size)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # add an Embedding Table for Character Embedding\n",
    "        self.token_embedding_table = nn.Embedding(VOCAB_SIZE, EMBEDDING_SIZE)\n",
    "        self.position_embedding_table = nn.Embedding(CONTEXT_SIZE, EMBEDDING_SIZE)\n",
    "        self.blocks = nn.Sequential(*[Block(NUM_HEADS, HEAD_SIZE) for _ in range(BLOCK_COUNT)])\n",
    "        self.ln_f = nn.LayerNorm(EMBEDDING_SIZE) # final layer norm\n",
    "        self.lm_head = nn.Linear(EMBEDDING_SIZE, VOCAB_SIZE)\n",
    "\n",
    "        # better init, not covered in the original GPT video, but important, will cover in followup video\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "    \n",
    "    def forward(self, x, y=None):\n",
    "        n_batch, n_context = x.shape\n",
    "\n",
    "        tok_emb = self.token_embedding_table(x) # (BATCH_SIZE, CONTEXT_SIZE, EMBEDDING_SIZE)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(0, n_context, device=device)) # position embedding for each char in CONTEXT (CONTEXT_SIZE, EMBEDDING_SIZE)\n",
    "        x = tok_emb + pos_emb # (BATCH_SIZE, CONTEXT_SIZE, EMBEDDING_SIZE)\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln_f(x) # (BATCH_SIZE, CONTEXT_SIZE, EMBEDDING_SIZE)\n",
    "        logits = self.lm_head(x) # (BATCH_SIZE, CONTEXT_SIZE, VOCAB_SIZE)\n",
    "        \n",
    "        if y is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            logits = logits.view(n_batch*n_context, VOCAB_SIZE)\n",
    "            y = y.view(n_batch*CONTEXT_SIZE)\n",
    "            loss = F.cross_entropy(logits, y)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, previous_text, max_new_tokens):\n",
    "        output = previous_text\n",
    "        for _ in tqdm(range(max_new_tokens)):\n",
    "            last_tokens = torch.tensor(encode(output[-CONTEXT_SIZE:]), device=device)\n",
    "            \n",
    "            # add batch dimension and feed to model\n",
    "            logits, _ = self(last_tokens.view(1, -1))\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            probs_next_char = probs[0, -1]\n",
    "            new_char = itos[torch.multinomial(probs_next_char, num_samples=1).item()]\n",
    "\n",
    "            output += new_char\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:02<00:00, 93.39it/s] \n",
      "100%|██████████| 200/200 [00:01<00:00, 104.23it/s]\n",
      "  0%|          | 1/5000 [00:04<5:49:53,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0/5000) train: 4.4371, val: 4.4379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 109.46it/s]\n",
      "100%|██████████| 200/200 [00:01<00:00, 136.39it/s]\n",
      " 10%|█         | 504/5000 [00:18<16:02,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500/5000) train: 2.6307, val: 2.6180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 109.07it/s]\n",
      "100%|██████████| 200/200 [00:01<00:00, 108.11it/s]\n",
      " 20%|██        | 1008/5000 [00:31<11:04,  6.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000/5000) train: 2.3817, val: 2.3719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 115.16it/s]]\n",
      "100%|██████████| 200/200 [00:01<00:00, 116.75it/s]\n",
      " 30%|███       | 1508/5000 [00:47<08:34,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1500/5000) train: 2.2576, val: 2.2529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 121.21it/s]]\n",
      "100%|██████████| 200/200 [00:01<00:00, 106.66it/s]\n",
      " 40%|████      | 2008/5000 [01:02<08:21,  5.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2000/5000) train: 2.1812, val: 2.1837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 122.84it/s]]\n",
      "100%|██████████| 200/200 [00:01<00:00, 110.03it/s]\n",
      " 50%|█████     | 2506/5000 [01:16<06:10,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2500/5000) train: 2.1469, val: 2.1635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 108.16it/s]]\n",
      "100%|██████████| 200/200 [00:02<00:00, 95.47it/s]\n",
      " 60%|██████    | 3007/5000 [01:31<05:50,  5.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3000/5000) train: 2.1238, val: 2.1259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 125.41it/s]]\n",
      "100%|██████████| 200/200 [00:01<00:00, 119.95it/s]\n",
      " 70%|███████   | 3505/5000 [01:45<05:05,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3500/5000) train: 2.1055, val: 2.1098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:02<00:00, 92.46it/s] ]\n",
      "100%|██████████| 200/200 [00:01<00:00, 103.38it/s]\n",
      " 80%|████████  | 4009/5000 [02:00<03:08,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4000/5000) train: 2.0823, val: 2.0922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 116.51it/s]]\n",
      "100%|██████████| 200/200 [00:01<00:00, 129.69it/s]\n",
      " 90%|█████████ | 4507/5000 [02:13<01:16,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4500/5000) train: 2.0724, val: 2.0769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [02:24<00:00, 34.71it/s]\n"
     ]
    }
   ],
   "source": [
    "model = Decoder()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for step in tqdm(range(MAX_STEPS)):\n",
    "    # calculate loss every once in a while\n",
    "    if step % EVAL_INTERVAL == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"Step {step}/{MAX_STEPS}) train: {losses['train']:.4f}, val: {losses['val']:.4f}\")\n",
    "\n",
    "    xb, yb = get_batch(\"train\")\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:09<00:00, 203.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "of the sive dat untulingene froned o2 froby an —\"\n",
      "Harliss now\"\n",
      "\u0002layintan its corthoatif be bed him flootheinne the. If sher thaom eand flioumie wlunes.” mome, and\n",
      "to grosyou now bad Propestly.f Halshing to\n",
      "hoks\n",
      "yod— \"\n",
      "\"I sud mone't sto lastes arod das and at and louct betaine he pottirsthing awallly dneck red Ronce. \"Chescorred sta mat cead\n",
      "aad Vottropsed to couldls. 7is\n",
      "Thim flabp int topichtly bbeuth dow Roff to said. Bangeld grous you -” Whe. Med. Thefthing wlouth Luncan's moppry groftie whe to\n",
      "a\n",
      "weamed eell andidling McAintion,\"\n",
      "“Wed ClanPlems to at? Chan'n that a happ af a h\u0002relver - beh pot for Ron, dating, ih ligced on the Pells. Harklef it ssose alock.\n",
      "EPelhilase. Dobed tlotl quice, at snomser arover tundheriftind,\" Cut He gughforgudtared iting lotgapetired hen of him scrounaled sapined thoated herl ldostpelf lad deyard were\n",
      "had and ssome cmiarion\n",
      "chack?\" - seeok are tichoset. “Ang fat—\n",
      "Ant\n",
      "Harry mipstorte Snw Pertrorg in her butoroun, tied gropo dubunn’th eexppiatined him titct posed alow voped wasl thermase gore wem\n",
      "lovef sof asided. Tefotedsos she. “So Sporragrig.\n",
      "“Hare Ond seenclyarr Whis bat come\n",
      "a cauroon wits grol, sorobow.\n",
      "\"I ?\" shad Bected sendil were caslicen growiD\n",
      "\"The, shosles jasers brod you hent . I’s the whe werer on ofw in  the mom him said award.\n",
      "”,\"was -! Dhack feast fas shorth Dup when trove Luet\n",
      "Hermomtin but trovemed frow bittolds fili) all awss hat coutcuile eh sfrod?”\n",
      "Dim, —\"\n",
      "With\n",
      "loss nate scane.\n",
      "D9\n",
      "Dummioning Mriteny you Blones the\n",
      "somes the\n",
      "a agastl \"That eplt he fizt sgecolly.”\n",
      "Or. \"Oh rett to bera’d in scone ow bearre Tof they shewigo're int the sing one coome batud\n",
      "and taill you bere the meals,-andser thro doouh a hobmidk and his to\n",
      "yound the weed foled.. “Sse, and --?\"fol, -- Buck wand. He him.”\n",
      "3! Thicks on of wens the momend and “On\n",
      "a ofte kne'.\n",
      "Alled, tepione. It Wequno them Halockelytin DeaR. .sid Itrmsoont Knarkly, yof gretw witthe tostyou, you knat watills thout seppered fant conled ded nowf aid A592’loight the Hermacted \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Inference (Generate Harry Potter'ish text)\n",
    "output = model.generate(\"\\n\", 2000)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
