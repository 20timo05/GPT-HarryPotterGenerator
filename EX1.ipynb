{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "The n-dimensional tensor mastery challenge: Combine the `Head` and `MultiHeadAttention` into one class that processes all the heads in parallel, treating the heads as another batch dimension (answer is in nanoGPT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Vocabulary\n",
    "path = './data/HarryPotterPreprocessed.txt'\n",
    "with open(path, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "chars = sorted(list(set(text)))\n",
    "\n",
    "# Tokenization\n",
    "stoi = {s:i for i, s in enumerate(chars)}\n",
    "itos = {i:s for s, i in stoi.items()}\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "VOCAB_SIZE = len(chars)\n",
    "EMBEDDING_SIZE = 32\n",
    "CONTEXT_SIZE = 8\n",
    "BATCH_SIZE = 64\n",
    "MAX_STEPS = 5000\n",
    "LEARNING_RATE = 3E-4\n",
    "BLOCK_COUNT = 2\n",
    "NUM_HEADS = 4\n",
    "DROPOUT = 0.2\n",
    "HEAD_SIZE = EMBEDDING_SIZE // NUM_HEADS # How big Query, Key and Value matrices are\n",
    "device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "EVAL_INTERVAL = 500\n",
    "EVAL_LOSS_BATCHES = 200\n",
    "\n",
    "this_model_name = \"model_EX1.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train & validation\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(data.shape[0] * 0.9)\n",
    "train_data, val_data = data[:n], data[n:]\n",
    "\n",
    "# Loader that returns a batch\n",
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(0, len(data) - CONTEXT_SIZE, (BATCH_SIZE, ))\n",
    "    x = torch.stack([data[i:i+CONTEXT_SIZE] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+CONTEXT_SIZE+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Multiple Heads of Self-Attention that are processed in parallel \"\"\"\n",
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "\n",
    "        # Single Heads in parallel\n",
    "        self.query = torch.randn([num_heads, EMBEDDING_SIZE, head_size]) * 0.02\n",
    "        self.key = torch.randn([num_heads, EMBEDDING_SIZE, head_size]) * 0.02\n",
    "        self.value = torch.randn([num_heads, EMBEDDING_SIZE, head_size]) * 0.02\n",
    "\n",
    "        self.dropout1 = nn.Dropout(DROPOUT)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(CONTEXT_SIZE, CONTEXT_SIZE)))\n",
    "        \n",
    "        # Only For Multi Head\n",
    "        self.proj = nn.Linear(num_heads*head_size, EMBEDDING_SIZE) # back to original size (see 3b1b Value↑ matrix)\n",
    "        self.dropout2 = nn.Dropout(DROPOUT)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        n_batch, n_context, n_emb = x.shape\n",
    "        num_heads, head_size = self.query.shape[0], self.query.shape[-1]\n",
    "\n",
    "        # (num_heads, n_batch, n_context, head_size)\n",
    "        q = torch.einsum('bxy,iyk->bxik', (x, self.query)).view(num_heads, n_batch, n_context, head_size)\n",
    "        k = torch.einsum('bxy,iyk->bxik', (x, self.key)).view(num_heads, n_batch, n_context, head_size)\n",
    "        v = torch.einsum('bxy,iyk->bxik', (x, self.value)).view(num_heads, n_batch, n_context, head_size)\n",
    "        \n",
    "        wei = q @ k.transpose(-2, -1) * q.shape[-1]**-0.5 # (num_heads, n_batch, n_context, n_context)\n",
    "        wei = wei.masked_fill(self.tril[:n_context, :n_context] == 0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1) # (num_heads, n_batch, n_context, n_context)\n",
    "        wei = self.dropout1(wei)\n",
    "\n",
    "        self.out = wei @ v # (num_heads, n_batch, n_context, head_size)\n",
    "        self.out = self.out.view(n_batch, n_context, num_heads*head_size)\n",
    "        self.out = self.dropout2(self.proj(self.out)) # (n_batch, n_context, EMBEDDING_SIZE)\n",
    "        return self.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, in_feat):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_feat, in_feat * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * in_feat, in_feat),\n",
    "            nn.Dropout(DROPOUT)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, dim, eps=1E-5):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.gamma = torch.ones(dim, device=device)\n",
    "        self.beta = torch.zeros(dim, device=device)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        var = x.var(-1, keepdim=True)\n",
    "        xhat = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        self.out = self.gamma * xhat + self.beta\n",
    "        return self.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer Block: Communication (MultiHead Attention) followed by computation (MLP - FeedForward)\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.sa_heads = CausalSelfAttention(n_heads, head_size)\n",
    "        self.ffwd = FeedForward(EMBEDDING_SIZE)\n",
    "\n",
    "        self.ln1 = LayerNorm(EMBEDDING_SIZE)\n",
    "        self.ln2 = LayerNorm(EMBEDDING_SIZE)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x + because their are residual connections around Masked Multi-Head Attention and Feed Forward (see Transformer Architecture)\n",
    "        x = x + self.sa_heads(self.ln1(x)) # (BATCH_SIZE, CONTEXT_SIZE, num_heads*head_size)\n",
    "        x = x + self.ffwd(self.ln2(x)) # (BATCH_SIZE, CONTEXT_SIZE, num_heads*head_size)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # add an Embedding Table for Character Embedding\n",
    "        self.token_embedding_table = nn.Embedding(VOCAB_SIZE, EMBEDDING_SIZE)\n",
    "        self.position_embedding_table = nn.Embedding(CONTEXT_SIZE, EMBEDDING_SIZE)\n",
    "        self.blocks = nn.Sequential(*[Block(NUM_HEADS, HEAD_SIZE) for _ in range(BLOCK_COUNT)])\n",
    "        self.ln_f = nn.LayerNorm(EMBEDDING_SIZE) # final layer norm\n",
    "        self.lm_head = nn.Linear(EMBEDDING_SIZE, VOCAB_SIZE)\n",
    "\n",
    "        # better init, not covered in the original GPT video, but important, will cover in followup video\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "    \n",
    "    def forward(self, x, y=None):\n",
    "        n_batch, n_context = x.shape\n",
    "\n",
    "        tok_emb = self.token_embedding_table(x) # (BATCH_SIZE, CONTEXT_SIZE, EMBEDDING_SIZE)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(0, n_context, device=device)) # position embedding for each char in CONTEXT (CONTEXT_SIZE, EMBEDDING_SIZE)\n",
    "        x = tok_emb + pos_emb # (BATCH_SIZE, CONTEXT_SIZE, EMBEDDING_SIZE)\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln_f(x) # (BATCH_SIZE, CONTEXT_SIZE, EMBEDDING_SIZE)\n",
    "        logits = self.lm_head(x) # (BATCH_SIZE, CONTEXT_SIZE, VOCAB_SIZE)\n",
    "        \n",
    "        if y is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            logits = logits.view(n_batch*n_context, VOCAB_SIZE)\n",
    "            y = y.view(n_batch*CONTEXT_SIZE)\n",
    "            loss = F.cross_entropy(logits, y)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, previous_text, max_new_tokens):\n",
    "        output = previous_text\n",
    "        for _ in tqdm(range(max_new_tokens)):\n",
    "            last_tokens = torch.tensor(encode(output[-CONTEXT_SIZE:]), device=device)\n",
    "            \n",
    "            # add batch dimension and feed to model\n",
    "            logits, _ = self(last_tokens.view(1, -1))\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            probs_next_char = probs[0, -1]\n",
    "            new_char = itos[torch.multinomial(probs_next_char, num_samples=1).item()]\n",
    "\n",
    "            output += new_char\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean loss for {EVAL_LOSS_BATCHES}x batches\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        losses = torch.zeros(EVAL_LOSS_BATCHES, device=device)\n",
    "        for i in tqdm(range(EVAL_LOSS_BATCHES)):\n",
    "            X, Y = get_batch(split)\n",
    "            _, loss = model(X, Y)\n",
    "            losses[i] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 49.09it/s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 63.54it/s]\n",
      "  0%|          | 4/5000 [00:07<1:58:07,  1.42s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0/5000) train: 4.4307, val: 4.4299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:02<00:00, 66.95it/s]]\n",
      "100%|██████████| 200/200 [00:03<00:00, 60.14it/s]\n",
      " 10%|█         | 506/5000 [00:27<26:08,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500/5000) train: 2.6391, val: 2.6246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:03<00:00, 55.95it/s]]\n",
      "100%|██████████| 200/200 [00:03<00:00, 59.50it/s]\n",
      " 20%|██        | 1005/5000 [00:49<28:28,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000/5000) train: 2.4151, val: 2.4116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:03<00:00, 59.41it/s]s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 61.39it/s]\n",
      " 30%|███       | 1504/5000 [01:10<31:29,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1500/5000) train: 2.3192, val: 2.2993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:06<00:00, 32.96it/s]s]\n",
      "100%|██████████| 200/200 [00:04<00:00, 43.40it/s]\n",
      " 40%|████      | 2004/5000 [01:48<58:50,  1.18s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2000/5000) train: 2.2506, val: 2.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:07<00:00, 26.94it/s]s]\n",
      "100%|██████████| 200/200 [00:07<00:00, 26.79it/s]s]\n",
      " 50%|█████     | 2501/5000 [02:37<1:36:19,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2500/5000) train: 2.2076, val: 2.2083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:03<00:00, 62.50it/s]s]  \n",
      "100%|██████████| 200/200 [00:03<00:00, 60.29it/s]\n",
      " 60%|██████    | 3006/5000 [03:01<11:54,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3000/5000) train: 2.1923, val: 2.1983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:03<00:00, 63.92it/s]s]\n",
      "100%|██████████| 200/200 [00:02<00:00, 70.99it/s]\n",
      " 70%|███████   | 3504/5000 [03:24<12:42,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3500/5000) train: 2.1726, val: 2.1736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:03<00:00, 57.80it/s]s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 54.01it/s]\n",
      " 80%|████████  | 4004/5000 [03:48<07:11,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4000/5000) train: 2.1571, val: 2.1518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:02<00:00, 67.03it/s]s]\n",
      "100%|██████████| 200/200 [00:03<00:00, 59.63it/s]\n",
      " 90%|█████████ | 4504/5000 [04:11<03:15,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4500/5000) train: 2.1410, val: 2.1442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [04:28<00:00, 18.60it/s]\n"
     ]
    }
   ],
   "source": [
    "model = Decoder()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for step in tqdm(range(MAX_STEPS)):\n",
    "    # calculate loss every once in a while\n",
    "    if step % EVAL_INTERVAL == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"Step {step}/{MAX_STEPS}) train: {losses['train']:.4f}, val: {losses['val']:.4f}\")\n",
    "\n",
    "    xb, yb = get_batch(\"train\")\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:04<00:00, 216.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ton as oves at chat lidnize nitts be this it his. PenumnaeMe andilm cione ceeart's\n",
      "Dery agearmben't mup the -fop a havet hand bardourp’t dic Verneare Andss he men the moss trely\n",
      "of the whe abe a noir mugh das at havery; he spalein was bad. A blemp of Crimsed. There’s'n Harry, it she noartedortpimedfonsed, suingly one, wald Ron.\n",
      "Harr; Dongefivell whis and but sils?”\n",
      "\"Sid nus ove\n",
      "wor\n",
      "bibe Prublet in. S, saigho bloplayblainbreathes; so?A pepthe boorey cumbrice wroundlou coven, jabcenuc of as closing arry. They edorich romts,beampolly and\n",
      "the, leired geee Maen he mi,\n",
      "sMe thand he thered's. Wealld yowad lik awed you're said notathe a\n",
      "got mapt, his beds, wexpblatathand the stalfoake coking the owakerstiss,\n",
      "lition at at omian. The gaming of and wharme.. Harry bund I to chiy offfotter.\n",
      "This te whe; yon to Me waslos uing k.” . ., Bec, harry pead the theing it,” said Sno?”\n",
      "\"Dunat and Tung could\u0002torned Mlyowly. I\n",
      "pide said\n",
      "HoAI geced for wich seaimsbelted exere a He fesiled andy”\n",
      "“Nast wald parry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Inference (Generate Harry Potter'ish text)\n",
    "model.eval()\n",
    "output = model.generate(\"\\n\", 1000)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
